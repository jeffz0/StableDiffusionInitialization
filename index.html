<!DOCTYPE html>
<!-- saved from url=(0071)https://www.danielbmckee.com/language-guided-music-for-video/index.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Google tag (gtag.js) -->
    <script async="" src="./js"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-GHV04V0Y92');
    </script>

    
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>Preserving Image Properties Through Initializations in Diffusion Models</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <!-- <meta property="og:image" content="https://www.danielbmckee.com/images/paper_teaser.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840"> -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://jeffz0.github.io/">
    <meta property="og:title" content="Preserving Image Properties Through Initializations in Diffusion Models">
    <!-- <meta property="og:description" content="" /> -->

    <!-- <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%F0%9F%8E%B5&lt;/text&gt;&lt;/svg&gt;"> -->


    <link rel="stylesheet" href="./bootstrap.min.css">
    <link rel="stylesheet" href="./font-awesome.min.css">
    <link rel="stylesheet" href="./codemirror.min.css">
    <link rel="stylesheet" href="./app.css">
    <link rel="stylesheet" href="./bootstrap.min(1).css">

    <script src="./jquery.min.js"></script>
    <script src="./bootstrap.min.js"></script>
    <script src="./codemirror.min.js"></script>
    <script src="./clipboard.min.js"></script>
    
    <script src="./app.js"></script>

    <link rel="stylesheet" href="./plyr.css">
    <script src="./plyr.js"></script>
    <link href="./bootstrap-icons.css" rel="stylesheet">

    <style>
        svg {
          width: 100%;
          height: auto;
        }
      </style>


    <style>
        .player-container {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
        }
        
        .player-container video {
            margin-right: 10px;
        }
    </style>

</head>

<body data-new-gr-c-s-check-loaded="14.1135.0" data-gr-ext-installed="">
    <div class="container" id="main" style="width: 100%;">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Preserving Image Properties Through Initializations in Diffusion Models<br>
                <small>
                    WACV 2024
                </small>
            </h2>
        </div>


        <!-- Authors and Affiliations -->
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://jeffz0.github.io/">
                          Jeffrey Zhang<sup>1, 2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://shaoyuc3.github.io/">
                          Shao-Yu Chang<sup>2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/kedanli">
                          Kedan Li<sup>1,2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="http://luthuli.cs.uiuc.edu/~daf/">
                            David Forsyth<sup>2</sup>
                        </a>
                    </li>
                </ul>
                <ul class="list-inline">
                    <li>
                        1 Revery AI Inc.
                    </li>
                    <li>
                        2 University of Illinois at Urbana-Champaign
                    </li>
                </ul>
            </div>
        </div>


        <!-- Materials Links -->
        <div class="row">
            <div class="col-sm-6 col-sm-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2306.09327">
                            <img src="./paper_thumbnail.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://www.youtube.com/watch?v=z6DBTAiLKzY">
                            <img src="./youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="https://github.com/user/project">
                            <img src="../project_page_template_files/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>  -->
                    </ul>
                </div>
        </div>

        <br>


        <!-- Abstract -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Retail photography imposes specific requirements on images.
                    For instance, images may need uniform background colors, consistent model poses, centered products, and consistent lighting.
                    Minor deviations from these standards impact a site’s aesthetic appeal, making the images unsuitable for use.
                    We show that Stable Diffusion methods, as currently applied, do not respect these requirements.
                    The usual practice of training the denoiser with a very noisy image and starting inference with a sample of pure noise leads to inconsistent generated images during inference.
                    This inconsistency occurs because it is easy to tell the difference between samples of the training and inference distributions.
                    As a result, a network trained with centered retail product images with uniform backgrounds generates images with erratic backgrounds.
                    The problem is easily fixed by initializing inference with samples from an approximation of noisy images.
                    However, in using such an approximation, the joint distribution of text and noisy image at inference time still slightly differs from that at training time.
                    This discrepancy is corrected by training the network with samples from the approximate noisy image distribution.
                    Extensive experiments on real application data show significant qualitative and quantitative improvements in performance from adopting these procedures.
                    Finally, our procedure can interact well with other control-based methods to further enhance the controllability of diffusion-based methods.
                </p>
            </div>
        </div>
        

        <!-- Video -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <iframe class="embedded_video" src="https://www.youtube.com/embed/z6DBTAiLKzY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
                </div>
            </div>
        </div>

        <br>


        <!-- Overview -->
        <div class="row">
            <div id="PlayBackRatePanelYPSC" class="PlayBackRatePanelYPSC" style="display: none; top: 2px; right: -44px; bottom: initial; left: initial;"><button id="SpeedUpYPSC" class="btnYPSC btnYPSC-right">&gt;&gt;</button><button id="PlayBackRateYPSC" class="btnYPSC">1.00</button><button id="SpeedDownYPSC" class="btnYPSC btnYPSC-left">&lt;&lt;</button><button id="SettingYPSC" class="btnYPSC"></button></div><div class="col-md-8 col-md-offset-2">
                <h3>
                    Overview
                </h3>

                <h4>
                    Training Dataset
                </h4>
                <p class="text-justify">
                    We collect over a million image pairs of retailer garment, garment on model, and garment text description triplets.
                    We are given one text prompt corresponding to a garment image and a model wearing that garment.
                </p>
                <img src="./images/dataset.png" alt="dataset" style="display: block; margin-left: auto; margin-right: auto; width: 100%;">
                <br>
                <h4>
                    PCA-K Offset Training + Inference
                </h4>
                <p class="text-justify">
                    We train a tri-modal model, which we call <code>ViML</code> for <code>Vi</code>deo to <code>M</code>usic with <code>L</code>anguage. The model fuses text and video input representations to query music samples. 
                    We rely on per-modality Transformer encoders to encode sequences of features from base encoders (CLIP and DeepSim) and a fusion model to combine the video and text encodings. For training, we introduce a text dropout regularization mechanism which we show is critical to model performance. 
                </p>
                <img src="./images/pipeline.png" alt="Model diagram" style="display: block; margin-left: auto; margin-right: auto; width: 70%;">

                <br>
                <h4>
                    Results
                </h4>
                <p class="text-justify">
                    Qualitatively, Mean Offset Training and Mean Offset Inference provides better text control because the relationship between initialization and text is preserved during training and inference.
                </p>

                <table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
                    <tr>
                        <th width="50%" valign="top" align="center">
                        <img src="./images/mean_blurred_inference.png" alt="sym" width="100%"></a>
                        <p style="line-height:1; font-size:10pt; text-align:center">DDIM Training + Mean Offset Inference</p>
                        </th>
                  
                        <th width="50%" valign="top" align="center">
                        <img src="./images/mean_blur_training.png" alt="sym" width="100%"></a>
                        <p style="line-height:1; font-size:10pt; text-align:center">Mean Offset Training + Inference (Ours)</p>
                        </th>
                    </tr>
                </table>

                <br>
                <h4>
                    Application to ControlNet
                </h4>
                <p class="text-justify">
                    We apply our method to ControlNet for the task of virtual try-on using our dataset.
                    We mask out the region of a garment from the person and adapt ControlNet to take the masked garment image as the condition. 
                </p>
                <img src="./images/controlnet.png" alt="controlnet" style="display: block; margin-left: auto; margin-right: auto; width: 100%;">
                
            </div>
        </div>

        <br>
        <!-- Citation -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <!-- <div class="form-group col-md-10 col-md-offset-1"> -->
                <table border="0">
                    <tbody>
                        <pre style=" display: block;
                            background: #eee;
                            white-space: pre;
                            -webkit-overflow-scrolling: touch;
                            max-width: 100%;
                            min-width: 100px;
                            border-radius: 20px;
                            ">
            
            @InProceedings{Zhang_2024_WACV,
                title={Preserving Image Properties Through Initializations in Diffusion Models},
                author={Zhang, Jeffrey and Chang, Shao-Yu and Li, Kedan and Forsyth, David},
                booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
                year={2024}
            }        
                        </pre>
                    </tbody>
                </table>
                <!-- <textarea id="bibtex" class="form-control" readonly="" style="display: none;">@InProceedings{Zhang_2024_WACV, 
                  author = {Zhang, Jeffrey and Chang, Shao-Yu and Li, Kedan and Forsyth, David},
                  title = {Preserving Image Properties Through Initializations in Diffusion Models},
                  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
                  year = {2024},
                }</textarea> -->
            </div>
        </div>

        <!-- Acknowledgements -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    Acknowlegdements
                </p> -->
                
                <p style="text-align:right">Website template credit: <a href="http://mgharbi.com/">Michaël Gharbi</a> and <a href="https://jonbarron.info/">Jon Barron</a></p>
            </div>
        </div>
    </div>
</body>
</html>
